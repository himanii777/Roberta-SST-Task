{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#======GPU assign=====#\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = \":4096:8\"\n",
    "\n",
    "\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device:', device)\n",
    "print('Current cuda device: ', torch.cuda.current_device())\n",
    "print('Count of using GPUs:', torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#====Packages====#\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModel,\n",
    "    AutoModelForCausalLM, #(Automatically loads a model for causal language modeling)\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoModelForTokenClassification,\n",
    "    AutoTokenizer,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    pipeline,\n",
    "    logging,\n",
    "    TrainerCallback\n",
    "    \n",
    ")\n",
    "from peft import LoraConfig, PeftModel, get_peft_model, PeftConfig\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "import csv\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    #np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    #torch.use_deterministic_algorithms(True)\n",
    "    #os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    #os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\"\n",
    "\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#======Check compatibility for precision training=======#\n",
    "\n",
    "# gpu_name = torch.cuda.get_device_name(0)\n",
    "# compute_capability = torch.cuda.get_device_capability(0)\n",
    "# print(f\"GPU Name: {gpu_name}\")\n",
    "# print(f\"Compute Capability: {compute_capability}\")\n",
    "\n",
    "\"\"\"\n",
    "If greater than 7 then we can set fp16 to True\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#======Model info======#\n",
    "\n",
    "model_name = \"roberta-base\" \n",
    "task_name = \"SST\"\n",
    "# output_dir = \".......\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=======Load dataset=======#\n",
    "\n",
    "dataset = load_dataset(\"glue\", \"sst2\", trust_remote_code=True)  \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\", add_prefix_space=True)\n",
    "\n",
    "\n",
    "# Limit training dataset if your gpu doesn't allow\n",
    "train_dataset = dataset[\"train\"].shuffle(seed=42).select(range(50000)) \n",
    "validation_dataset = dataset[\"validation\"]\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"sentence\"],  # sst uses \"sentence\" as input\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128,\n",
    "    )\n",
    "    tokenized_inputs[\"labels\"] = examples[\"label\"]  \n",
    "    return tokenized_inputs\n",
    "\n",
    "train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "validation_dataset = validation_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "train_dataset = train_dataset.remove_columns([\"idx\", \"sentence\"])  \n",
    "train_dataset.set_format(\"torch\")  \n",
    "\n",
    "validation_dataset = validation_dataset.remove_columns([\"idx\", \"sentence\"])\n",
    "validation_dataset.set_format(\"torch\")\n",
    "\n",
    "train_dataset.set_format(\"torch\", device=\"cuda:0\")\n",
    "validation_dataset.set_format(\"torch\", device=\"cuda:0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#====== Load LLM for SST-2 ======#\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"roberta-base\", \n",
    "    num_labels=2,  \n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\", add_prefix_space=True)  \n",
    "tokenizer.pad_token = tokenizer.eos_token  \n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=128, \n",
    "    lora_alpha=64,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",  \n",
    "    task_type=\"SEQ_CLS\", \n",
    ")\n",
    "\n",
    "model = get_peft_model(model, peft_config)\n",
    "model = model.to(\"cuda:0\")\n",
    "\n",
    "\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")\n",
    "\n",
    "# Check if LoRA layers are correctly loaded\n",
    "# print(\"LoRA layers in the model:\")\n",
    "# for name, param in model.named_parameters():\n",
    "#     if \"lora\" in name.lower():\n",
    "#         print(f\"{name}: Trainable = {param.requires_grad}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=======Set training parameters=======#\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=4,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=1,\n",
    "    optim=\"adamw_hf\",\n",
    "    save_strategy=\"epoch\",  \n",
    "    evaluation_strategy=\"epoch\", \n",
    "    learning_rate=3e-4,\n",
    "    weight_decay=0.01,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    max_grad_norm=1.0,  \n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.06,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    report_to=\"tensorboard\",\n",
    "    logging_dir=\"------\",\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=2\n",
    ")\n",
    "\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def training_step(self, model, inputs):\n",
    "        # Move all inputs to cuda:0\n",
    "        inputs = {k: v.to(\"cuda:0\")  for k, v in inputs.items()}\n",
    "        return super().training_step(model, inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======Start Training======#\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=model,  \n",
    "    args=training_arguments,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=validation_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=========In/OOD benchmark eval=========#\n",
    "\n",
    "benchmarks = {\n",
    "    \"sst2_test\": load_dataset(\"glue\", \"sst2\", split=\"validation\"),\n",
    "    \"imdb_test\": load_dataset(\"imdb\", split=\"test\")\n",
    "}\n",
    "\n",
    "def preprocess_sst2(examples, tokenizer):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"sentence\"], truncation=True, padding=\"max_length\",\n",
    "        max_length=128,\n",
    "    )\n",
    "    tokenized_inputs[\"labels\"] = examples[\"label\"]\n",
    "    return tokenized_inputs\n",
    "\n",
    "def preprocess_imdb(examples, tokenizer):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"text\"], truncation=True, padding=\"max_length\",\n",
    "        max_length=128,\n",
    "    )\n",
    "    tokenized_inputs[\"labels\"] = examples[\"label\"]\n",
    "    return tokenized_inputs\n",
    "\n",
    "def evaluate_model_from_path(model_path, benchmarks, batch_size=32):\n",
    "    adapter_config = PeftConfig.from_pretrained(model_path)\n",
    "    base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        adapter_config.base_model_name_or_path,\n",
    "        num_labels=2\n",
    "    ).to(\"cuda:0\")\n",
    "    model = PeftModel.from_pretrained(base_model, model_path).eval()\n",
    "    tokenizer = AutoTokenizer.from_pretrained(adapter_config.base_model_name_or_path, add_prefix_space=True)\n",
    "\n",
    "    in_distribution = [\"sst2_test\"]\n",
    "    out_of_distribution = [\"imdb_test\"]\n",
    "\n",
    "    in_acc_total, out_acc_total = 0.0, 0.0\n",
    "    in_count, out_count = 0, 0\n",
    "\n",
    "    for dataset_name, dataset in benchmarks.items():\n",
    "        print(f\"Evaluating on {dataset_name}...\")\n",
    "\n",
    "        if dataset_name == \"sst2_test\":\n",
    "            tokenized_dataset = dataset.map(\n",
    "                lambda x: preprocess_sst2(x, tokenizer),\n",
    "                batched=True,\n",
    "                remove_columns=[col for col in dataset.column_names if col not in [\"label\"]]\n",
    "            )\n",
    "        else:\n",
    "            tokenized_dataset = dataset.map(\n",
    "                lambda x: preprocess_imdb(x, tokenizer),\n",
    "                batched=True,\n",
    "                remove_columns=[col for col in dataset.column_names if col not in [\"label\"]]\n",
    "            )\n",
    "\n",
    "        tokenized_dataset.set_format(\"torch\")\n",
    "\n",
    "        data_loader = torch.utils.data.DataLoader(\n",
    "            tokenized_dataset,\n",
    "            batch_size=batch_size,\n",
    "            collate_fn=lambda x: {\n",
    "                key: torch.stack([example[key] for example in x]).to(\"cuda:0\")\n",
    "                for key in [\"input_ids\", \"attention_mask\", \"labels\"]\n",
    "            },\n",
    "        )\n",
    "\n",
    "        all_predictions, all_labels = [], []\n",
    "\n",
    "        for batch in data_loader:\n",
    "            inputs = {k: batch[k] for k in [\"input_ids\", \"attention_mask\"]}\n",
    "            labels = batch[\"labels\"]\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**inputs)\n",
    "                predictions = outputs.logits.argmax(dim=-1).cpu().numpy()\n",
    "\n",
    "            all_predictions.extend(predictions)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        acc = accuracy_score(all_labels, all_predictions)\n",
    "        print(f\"{dataset_name} Accuracy: {acc:.4f}\")\n",
    "\n",
    "        report = classification_report(all_labels, all_predictions, zero_division=0)\n",
    "        print(f\"Classification Report:\\n{report}\")\n",
    "\n",
    "        if dataset_name in in_distribution:\n",
    "            in_acc_total += acc\n",
    "            in_count += 1\n",
    "        elif dataset_name in out_of_distribution:\n",
    "            out_acc_total += acc\n",
    "            out_count += 1\n",
    "\n",
    "    avg_in_acc = in_acc_total / in_count if in_count > 0 else 0.0\n",
    "    avg_out_acc = out_acc_total / out_count if out_count > 0 else 0.0\n",
    "\n",
    "    print(f\"Average In-Distribution Accuracy: {avg_in_acc:.4f}\")\n",
    "    print(f\"Average Out-of-Distribution Accuracy: {avg_out_acc:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"avg_in_distribution_accuracy\": avg_in_acc,\n",
    "        \"avg_out_of_distribution_accuracy\": avg_out_acc\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fine_tuned_model_path = \"---------------\"\n",
    "evaluate_model_from_path(fine_tuned_model_path, benchmarks, batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
